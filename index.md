---
layout: default
---

# Workshop Description

Mathematical optimization underpins many applications across science and
engineering, as it provides a set of formal tools to compute the ‘best’
action, design, control, or model from a set of possibilities. In data
science, machine learning, and artificial intelligence, mathematical
optimization is the engine of model training and learning. This workshop will
provide an overview of the key elements of this topic (unconstrained,
constrained, convex optimization, optimization for model training), and will
have a practical focus, with participants formulating and solving optimization
problems early and often using standard modeling languages and solvers. By
introducing common models from machine learning and other fields, this
workshop aims to make participants comfortable with optimization tools so that
they may use it for rapid prototyping and experimentation in their own work.
Students should be comfortable with linear algebra, differential multivariable
calculus, and basic probability and statistics. Experience with Python will be
helpful, but not required.

Topics to be discussed in this workshop include:

* Formulating optimization problems
* Fundamentals of constrained and unconstrained optimization
* Convex optimization
* Optimization methods for model fitting in machine learning
* Optimization in Python using SciPy and CVXPY
* In-depth Jupyter Notebook examples from machine learning, statistics, and other fields.

## About the Instructor

![Kevin Carlberg](/assets/img/profile.jpg){:style="max-width:30%;"}

[Kevin Carlberg](https://kevintcarlberg.net) is an AI Research Science Manager at Meta
Reality Labs and an Affiliate Associate Professor of Applied Mathematics and
Mechanical Engineering at the University of Washington. He leads a research
team focused on enabling the future of augmented and virtual reality through
AI-driven innovations. His individual research combines concepts from machine
learning, computational physics, and high-performance computing to drastically
reduce the cost of simulating nonlinear dynamical systems at extreme scale.
Previously, Kevin was a Distinguished Member of Technical Staff at Sandia
National Laboratories in Livermore, California, where he led a research group
of PhD students, postdocs, and technical staff in applying these techniques to
a range of national-security applications in mechanical and aerospace
engineering.

# Workshop Materials

## Pre-workshop Checklist

**Step 1: Join the class Piazza**
We will be using Piazza for questions and answers. Piazza will allow you to ask questions to the instructors before or during the class. Here is how to sign up:
- Go to the [class signup page](https://piazza.com/stanford/spring2022/icmeswml). You should see a website that looks like the image below:
![Piazza Signup Page](/assets/img/piazza_signup_page.PNG)
- **The listed term for the course is Spring 2022, which is incorrect. However, this is still the correct class** (there was a clerical error made when setting up the class). Join the class by entering in Class Access Code icme2022optimization.
- You may need to provide an email address if you do not already have a Piazza account
Once you've joined the class, you can submit questions by clicking the blue **New Post** button at the top left of the webpage.

**Step 2: Fill out the pre-course survey**
Please fill out this quick 2-minute [pre-course survey](https://forms.gle/8P4392TUFTVW5pMp7)! You will need so sign in with your email address to fill out this form.
Filling this out will help us tweak the course contents to meet your needs!

**Step 3: Access the course contents**
The course slides and tutorials are available via Google Drive. Here is how to access the course contents:
- Go to [https://drive.google.com](https://drive.google.com) and log in with your Google
  account
- Go to [https://tinyurl.com/icmemathopt2022](https://tinyurl.com/icmemathopt2022) to access
  the shared Google Drive folder
- Click on "ICME Summer Workshop 2022 - Introduction to Mathematical Optimization" > "Add Shortcut to Drive".

**Step 4: Try out the tutorials for yourself!**
The class tutorials are hosted on Google Collab. [Google Colab](https://colab.research.google.com/) is a free cloud-based Jupyter Notebook environment.
The Python Notebooks in this course’s shared Drive contain real-world examples of optimization problems that you can explore and study by running them using Google Colab. Here are the steps to get started:
- In Google Drive, go to "ICME Summer Workshop 2022 - Introduction To Mathematical
  Optimization" > "Notebooks"
- Double click any notebook
- You now have three options:
  1. *Look at the notebook and its output*: Simply scroll around.
  2. *Interact with the notebook*: Feel free to modify the notebook and run it
     with modifications. However, because this remains part of the original folder, you
     do not have edit permissions and your changes won't be saved after
       exiting.
  3. *Make a copy of the notebook*: Click on “Copy to Drive” at the top, which will create a copy in "My Drive" > "Colab Notebooks". **This is your own separate copy.**

## Schedule

#### Session 1 (Friday, August 5, 1:00 - 2:30 P.M. PST)
  - Introduction to optimization
  - Unconstrained optimization

#### Session 2 (Friday, August 5, 2:45 - 4:00 P.M. PST)
  - Optimization in Python

#### Session 3 (Monday, August 8, 1:00 - 2:15 P.M. PST)
  - Constrained optimization
  - Optimization for machine learning

#### Session 4 (Monday, August 8, 2:30 - 4:00 P.M. PST)
  - Convex optimization
  - Convex optimization examples
  - Closing Q&A

## Workshop Recordings
#### [Day 1 (Friday, August 5)](https://stanford.zoom.us/rec/share/_ywxfX_zDiEELl91GqXnInUqg112R0hqyOaY1z_FwqROd9oYaFdbHWpbXwRKc7xS.nQaNYQtMeXAJemf2?startTime=1659728459000)
#### [Day 2 (Monday, August 8)](https://stanford.zoom.us/rec/share/1Aahw88UPIWLFUNcIIyszlib3lZQElZcYSZ-naH3Ju82e2EipQ85yEMMky2_s43J.lRTYbp1NdOr9Zu9Q?startTime=1659987873000)

## Additional Resources

Here are some additional resources for various topics:

- J. Nocedal and S. J. Wright. *Numerical Optimization*, Springer, 1999.
- S. Boyd and L. Vadenberghe. *Convex Optimization*, Cambridge University
  Press, 2004. [(available online)](http://stanford.edu/~boyd/cvxbook/)
  - Excellent lectures by S. Boyd online
  - Class notes and lectures for
    [EE364a](http://web.stanford.edu/class/ee364a/),
    [EE364b](http://web.stanford.edu/class/ee364b/) online
	- [CVX101 MOOC](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)
- P.E. Gill, W. Murray, and M.H. Wright, *Practical Optimization*, London,
  Academic Press, 1981.
- Bottou, L., Curtis, F.E. and Nocedal, J., 2018. Optimization methods for
  large-scale machine learning. SIAM Review, 60(2), pp.223-311. [(available on
  the arXiv)](https://arxiv.org/abs/1606.04838) (Advanced review article)
